{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocessing import parse_annotation\n",
    "from frontend import YOLO\n",
    "import json\n",
    "#from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"test/config.json\"\n",
    "with open(config_path) as config_buffer:    \n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['env']['gpu']\n",
    "gpus = len(config['env']['gpu'].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen labels:{'RBC': 3854}\n",
      "Given labels:['RBC']\n",
      "Overlap labels:{'RBC'}\n",
      "(13, 13)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 13, 13, 1024) 50547936    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 30)   30750       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 6) 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1, 1, 3, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 13, 13, 5, 6) 0           reshape_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,578,686\n",
      "Trainable params: 50,558,014\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "18/4 [=======================================================================================================================================] - 20s 1s/step - loss: 0.1851 - val_loss: 0.2042\n",
      "Epoch 2/200\n",
      "18/4 [=======================================================================================================================================] - 10s 537ms/step - loss: 0.0897 - val_loss: 0.1950\n",
      "Epoch 3/200\n",
      "18/4 [=======================================================================================================================================] - 10s 534ms/step - loss: 0.0674 - val_loss: 0.2158\n",
      "Epoch 4/200\n",
      "18/4 [=======================================================================================================================================] - 10s 552ms/step - loss: 0.0555 - val_loss: 0.1629\n",
      "Epoch 5/200\n",
      "18/4 [=======================================================================================================================================] - 9s 517ms/step - loss: 0.0471 - val_loss: 0.0742\n",
      "Epoch 6/200\n",
      "18/4 [=======================================================================================================================================] - 10s 551ms/step - loss: 0.0385 - val_loss: 0.0414\n",
      "Epoch 7/200\n",
      "18/4 [=======================================================================================================================================] - 9s 520ms/step - loss: 0.0317 - val_loss: 0.0309\n",
      "Epoch 8/200\n",
      "18/4 [=======================================================================================================================================] - 9s 513ms/step - loss: 0.0267 - val_loss: 0.0260\n",
      "Epoch 9/200\n",
      "18/4 [=======================================================================================================================================] - 10s 537ms/step - loss: 0.0230 - val_loss: 0.0239\n",
      "Epoch 10/200\n",
      "18/4 [=======================================================================================================================================] - 9s 521ms/step - loss: 0.0211 - val_loss: 0.0203\n",
      "Epoch 11/200\n",
      "18/4 [=======================================================================================================================================] - 10s 536ms/step - loss: 0.0199 - val_loss: 0.3325\n",
      "Epoch 12/200\n",
      "18/4 [=======================================================================================================================================] - 10s 542ms/step - loss: 0.2389 - val_loss: 0.3565\n",
      "Epoch 13/200\n",
      "18/4 [=======================================================================================================================================] - 10s 536ms/step - loss: 0.1860 - val_loss: 0.2216\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "#   Parse the annotations \n",
    "###############################\n",
    "\n",
    "# parse annotations of the training set\n",
    "train_imgs, train_labels = parse_annotation(config['train']['train_annot_folder'], \n",
    "                                            config['train']['train_image_folder'], \n",
    "                                            config['model']['labels'], \".jpg\")\n",
    "\n",
    "# parse annotations of the validation set, if any, otherwise split the training set\n",
    "if os.path.exists(config['valid']['valid_annot_folder']):\n",
    "    valid_imgs, valid_labels = parse_annotation(config['valid']['valid_annot_folder'], \n",
    "                                                config['valid']['valid_image_folder'], \n",
    "                                                config['model']['labels'], \".jpg\")\n",
    "else:\n",
    "    train_valid_split = int(0.8*len(train_imgs))\n",
    "    np.random.shuffle(train_imgs)\n",
    "    \n",
    "    valid_imgs = train_imgs[train_valid_split:]\n",
    "    train_imgs = train_imgs[:train_valid_split]\n",
    "\n",
    "\n",
    "overlap_labels = set(config['model']['labels']).intersection(set(train_labels.keys()))\n",
    "\n",
    "print ('Seen labels:{}'.format(train_labels))\n",
    "print ('Given labels:{}'.format(config['model']['labels']))\n",
    "print ('Overlap labels:{}'.format(overlap_labels))    \n",
    "\n",
    "if len(overlap_labels) < len(config['model']['labels']):\n",
    "    print ('Some labels have no images! Please revise the list of labels in the config.json file!')\n",
    "else:\n",
    "    ###############################\n",
    "    #   Construct the model \n",
    "    ###############################\n",
    "\n",
    "    yolo = YOLO(architecture        = config['model']['architecture'],\n",
    "                input_size          = config['model']['input_size'], \n",
    "                labels              = config['model']['labels'], \n",
    "                max_box_per_image   = config['model']['max_box_per_image'],\n",
    "                anchors             = config['model']['anchors'],\n",
    "                gpus                = gpus)\n",
    "\n",
    "    ###############################\n",
    "    #   Load the pretrained weights (if any) \n",
    "    ############################### \n",
    "    \n",
    "    if os.path.exists(config['train']['pretrained_weights']):\n",
    "       print (\"Loading pre-trained weights in {}\".format(config['train']['pretrained_weights']))\n",
    "       yolo.load_weights(config['train']['pretrained_weights'])\n",
    "\n",
    "    ###############################\n",
    "    #   Start the training process \n",
    "    ###############################\n",
    "    #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    yolo.train(train_imgs         = train_imgs,\n",
    "              valid_imgs         = valid_imgs,\n",
    "              train_times        = config['train']['train_times'],\n",
    "              valid_times        = config['valid']['valid_times'],\n",
    "              nb_epoch           = config['train']['nb_epoch'], \n",
    "              learning_rate      = config['train']['learning_rate'], \n",
    "              batch_size         = config['train']['batch_size'],\n",
    "              warmup_bs          = config['train']['warmup_batches'],\n",
    "              object_scale       = config['train']['object_scale'],\n",
    "              no_object_scale    = config['train']['no_object_scale'],\n",
    "              coord_scale        = config['train']['coord_scale'],\n",
    "              class_scale        = config['train']['class_scale'],\n",
    "              saved_weights_name = config['train']['saved_weights_name'],\n",
    "              debug              = config['train']['debug'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
